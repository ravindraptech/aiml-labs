{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239bf6b6-f5e7-4d63-bc73-7df6eec38b29",
   "metadata": {},
   "source": [
    "# Instruction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc41d1-1c8a-4dcb-83b4-ae4fbc625219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import jsonlines\n",
    "\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "from llama import BasicModelRunner\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed2178-c2f5-43c3-bef3-b22a92610fe6",
   "metadata": {},
   "source": [
    "# Load instruction tuned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e294cb6-5fe1-4505-93b9-797e67441997",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f953b2c-bd74-4671-bcdf-de06a5f54746",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5\n",
    "print(\"Instruction-tuned dataset:\")\n",
    "top_m = list(itertools.islice(instruction_tuned_dataset, m))\n",
    "for j in top_m:\n",
    "  print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab277b65-98ca-4f20-9938-72925b9cb94a",
   "metadata": {},
   "source": [
    "# Two prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bb8f8-8f70-462b-a4df-a08ddb74c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef963c4e-9a22-4097-ae01-3e4f7afc082c",
   "metadata": {},
   "source": [
    "# Hydrate prompts (add data to prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a38bac-7985-48ba-bea1-c0e6fa89eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for j in top_m:\n",
    "  if not j[\"input\"]:\n",
    "    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n",
    "  else:\n",
    "    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n",
    "\n",
    "  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb13a2-afba-4e5c-8881-de51519b03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(processed_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
